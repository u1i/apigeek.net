# Пробуждение Силы ИИ

Помните, как GPT от OpenAI был выбором по умолчанию для большинства проектов ИИ? Теперь ландшафт ИИ перевернулся с ног на голову всего за несколько месяцев, поскольку такие технологические гиганты, как Meta, Microsoft, Databricks и Apple, выпустили свои собственные открытые модели. Давайте посмотрим, как эта новая эра выбора и доступности меняет то, как мы создаем интеллектуальные приложения, почему не существует универсального решения и как вы можете ориентироваться в этом быстро развивающемся ландшафте, чтобы найти наилучший подход, соответствующий вашим потребностям.

До конца прошлого года, когда меня спрашивали о создании интеллектуальных приложений с использованием ИИ, я неохотно признавал, что GPT от OpenAI, вероятно, был единственным жизнеспособным вариантом в то время. Это было похоже на наличие ящика с инструментами, в котором есть только один инструмент - или, скажем, много мощных инструментов, но все они от одного бренда, с одинаковыми ограничениями и особенностями. Я хорошо знаком с семейством GPT, поработав с GPT-2, GPT-3 и всеми вариантами .5 и turbo. Не поймите меня неправильно, они великолепны, но, как я уже сказал, все они от одной компании. Ранее я писал о необходимости плана Б. Что происходит, когда ваш привычный API большой языковой модели внезапно устаревает и заменяется новым?

## Революция Моделей ИИ: Появление Разнообразной Экосистемы

Но затем, всего за несколько месяцев, все изменилось. Anthropic и Google выпустили передовые модели ИИ, которые почти так же мощны, как и модели OpenAI. Что еще более важно, такие технологические гиганты, как Meta, Apple и Microsoft, сделали свои модели открытым исходным кодом и доступными для скачивания. Это означает, что вы можете запускать их на своей собственной инфраструктуре, а не просто получать доступ к ним через API, что некоторым людям не нравится, поскольку это подразумевает отправку ваших данных в неизвестность.

Внезапно мой ящик с инструментами был переполнен сверкающими новыми инструментами, каждый из которых обладал своими уникальными функциями и возможностями, и ландшафт моделей ИИ превратился в разнообразную экосистему. Некоторые из этих новых открытых моделей, такие как Llama 3, теперь так же мощны, как GPT всего 1,5 года назад, а некоторые, невероятно, даже могут работать на моем MacBook Air! Это было похоже на наблюдение за тем, как черно-белый мир внезапно взрывается цветом, поскольку ИИ стал более доступным и универсальным, чем когда-либо прежде. Давайте рассмотрим некоторые из наиболее важных релизов за последние несколько месяцев.

## Недавние Достижения в Больших Языковых Моделях

• Google Gemini (6 декабря 2023 г.): Продвинутая линейка моделей Google, включая версии 1.0, 1.5 (Pro и Ultra) с контекстными окнами до 1 миллиона токенов - я довольно много работал с ними и мне действительно нравится, как они развиваются.
• Mixtral от Mistral (11 декабря 2023 г.): выпуск Mixtral 8x7B, высококачественной разреженной смеси экспертных моделей (SMoE) с открытыми весами, которая соответствует или превосходит GPT3.5 по большинству стандартных тестов. До этого момента я не слишком много изучал модели Mistral.
• Gemma от Google (21 февраля 2024 г.): Семейство легковесных, современных открытых моделей, созданных на основе тех же исследований и технологий, что и модели Gemini от Google, делающих продвинутый ИИ более доступным для разработчиков. Это удивительно маленькие модели, и когда я попробовал их, я понял, что для некоторых случаев использования нам действительно нужен только движок, который может понимать язык и взаимодействовать с пользователями. Теперь мы можем встроить эти возможности в программное обеспечение, которое я могу запускать на своей собственной машине, и мне не нужно полагаться на OpenAI.
• Anthropic Claude 3 (4 марта 2024 г.): Последние предложения Anthropic включают Haiku, Sonnet и Opus, и мне посчастливилось иметь исследовательский доступ к этим моделям в течение некоторого времени. На мой взгляд, на данный момент они являются наиболее мощными альтернативами моделям OpenAI. Особенно Opus кажется теплым, увлекательным и является невероятной моделью для создания цифровых личностей, которые могут участвовать в глубоких интеллектуальных беседах и демонстрировать продвинутые способности рассуждения.
• Grok от X (выпущен 18 марта 2024 г.): Объявлен как «модель языка с открытым исходным кодом», компания выпустила для публики только веса, без кода или большой документации, оставив многих разработчиков в неуверенности относительно ее реальных возможностей и удобства использования. Я бы с удовольствием попробовал ее, но сейчас она слишком велика, чтобы запускать ее на собственном оборудовании или в облаке.
• MM1 от Apple (выпущен 19 марта 2024 г.): мультимодальная большая языковая модель, которая ясно указывает на тот факт, что Apple очень серьезно относится к ИИ. У меня еще не было возможности попробовать ее.
• DBRX от Databricks (27 марта 2024 г.): Открытая модель, которая вводит архитектуру смеси экспертов (MoE) с мелким зерном, достигая впечатляющей производительности с меньшим количеством параметров, чем GPT. Это может быть очень интересно для корпоративных компаний, поскольку дает им возможность запускать мощные модели ИИ на собственной инфраструктуре. Ориентация Databricks на потребности предприятий, такие как соответствие данных и возможность тонкой настройки моделей для конкретных случаев использования, делает DBRX привлекательным вариантом для многих компаний.
• Llama 3 от Meta (18 апреля 2024 г.): Последняя открытая модель Meta, обученная на огромном наборе данных и предлагающая производительность, сопоставимую с GPT всего 1,5 года назад. Я очень, очень впечатлен качеством вывода, тем, как она реагирует на пользовательские подсказки, и тем, насколько она универсальна и удобна в использовании. Конечно, я видел LLama 2 раньше, но не так много использовал ее. Facebook, WhatsApp и Instagram теперь имеют встроенные возможности, работающие на LLama 3. Когда вы думаете о том, насколько большой проблемой для компаний, занимающихся ИИ, является получение свежих данных для обучения своих моделей, подумайте о том, сколько миллиардов пользователей у этих платформ. Meta находится в отличном положении. Обучение с подкреплением с человеческой обратной связью является ключом к тому, чтобы сделать модели ИИ умнее и создать следующее поколение.
• Phi-3 от Microsoft (23 апреля 2024 г.): Семейство небольших языковых моделей (SLM), разработанных для эффективности и производительности, особенно хорошо подходящих для периферийных вычислений и автономных сценариев. Мне понравился мой первый набор взаимодействий с моделями Phi-3, и я считаю, что они найдут прочную нишу в приложениях, которые отдают приоритет скорости, конфиденциальности и возможностям устройства, а не сырой мощности.

Эта временная шкала показывает быстрые темпы инноваций и растущее разнообразие ландшафта моделей ИИ всего за несколько месяцев. Каждый выпуск приносит новые возможности, архитектуры и потенциальные варианты использования, предоставляя разработчикам и компаниям множество вариантов на выбор.

## OpenAI и Рост Более Эффективных Архитектур ИИ

Но где же OpenAI во всем этом? Компания, которая управляет ультра-известным ChatGPT и по-прежнему доминирует на большей части ландшафта ИИ со своими моделями GPT, заметно отсутствовала в недавней волне релизов (если на мгновение проигнорировать объявление SORA). Хотя они могут работать над GPT-5 за кулисами, ясно, что некоторые из новейших архитектур, особенно те, которые используют методы смеси экспертов (MoE), начинают бросать вызов превосходству GPT.

Такие модели, как DBRX и Llama 3, продемонстрировали, что можно добиться впечатляющей производительности с меньшим количеством параметров и более эффективными архитектурами. И переход к моделям MoE, которые могут давать лучшие результаты с меньшими требованиями к инфраструктуре, фактически съедает обед OpenAI, разрушая конкурентное преимущество, которым когда-то обладал GPT.

Итак, как же нам ориентироваться в этой новой эре выбора моделей ИИ и их доступности, чтобы найти наиболее подходящий вариант для наших потребностей?

## Использование Разнообразия Моделей ИИ

Пока мы ориентируемся в этой новой эре выбора и доступности моделей ИИ, важно признать, что не существует универсального решения. Подобно тому, как наш мозг использует разные системы для различных задач, от автоматических и бессознательных (например, завязывание шнурков) до обдуманных и аналитических (например, решение сложной математической задачи), мы можем использовать разные модели ИИ для конкретных целей.

В своей книге «Думай медленно... решай быстро» психолог Даниэль Канеман вводит понятие двух различных систем в нашем сознании: Система 1, которая работает автоматически и быстро, и Система 2, которая выделяет внимание на более трудоемкие умственные действия. Мы можем применить эту концепцию к миру моделей ИИ, используя меньшие, более эффективные модели для задач, требующих быстрых ответов и минимальных вычислительных ресурсов (подобно Системе 1), и более крупные, сложные модели для задач, требующих более глубокого рассуждения и анализа (подобно Системе 2).

Более того, мы можем комбинировать модели, которые превосходят в конкретных задачах, чтобы создавать мощные, многогранные системы ИИ. Например, мы можем использовать такую модель, как Phi-3, для периферийных вычислений и автономных сценариев, Gemma - для легкой обработки на устройстве, а DBRX или Llama 3 - для более сложных задач, основанных на облачных технологиях. Понимая сильные и слабые стороны каждой модели и стратегически комбинируя их, мы можем создавать приложения ИИ, которые более эффективны, результативны и адаптируемы к широкому спектру вариантов использования.

## Вы Можете Использовать Гибкий, Информированный Подход

В конечном счете, ключом к успеху в этом новом ландшафте является подход к выбору и развертыванию моделей ИИ с гибким, информированным мышлением. Разработчики и компании могут использовать возможности этой новой эры ИИ, избегая при этом ловушек чрезмерной зависимости от какой-либо одной модели или поставщика, следя за последними разработками, экспериментируя с различными моделями и тщательно учитывая конкретные потребности и ограничения каждого проекта.

Это захватывающее время для ИИ, и по мере того, как мы движемся вперед, давайте примем разнообразие и доступность ландшафта моделей ИИ, поскольку это явно представляет собой значительный шаг вперед в демократизации и развитии искусственного интеллекта.