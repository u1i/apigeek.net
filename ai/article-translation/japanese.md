# 目覚めるAIの力

OpenAIのGPTがほとんどのAIプロジェクトのデフォルトの選択肢だったことを覚えていますか？今や、わずか数ヶ月でAIの状況は一変し、Meta、Microsoft、Databricks、Appleなどの大手テック企業が独自のオープンモデルをリリースしています。この新しい選択肢と利用しやすさの時代が、スマートアプリケーションの構築方法をどのように変えているのか、なぜワンサイズフィットオールの解決策がないのか、そして、急速に進化するこの状況の中で、自分のニーズに最も適したアプローチを見つけるにはどうすればよいのかを見ていきましょう。

昨年末まで、AIを使ってスマートアプリケーションを構築することについて聞かれれば、当時はOpenAIのGPTがおそらく唯一の実行可能な選択肢だったと、渋々ながら認めていたでしょう。それは、ツールが1つしかない工具箱のようなものでした。あるいは、多くの強力なツールがあるが、すべて同じブランドで、同じ制限と癖があるとも言えます。私はGPT-2、GPT-3、そしてすべての.5とターボのバリエーションを使って仕事をしてきたので、GPTファミリーにはよく精通しています。誤解しないでください。それらは素晴らしいものですが、先ほど言ったように、すべて1つの会社のものなのです。以前、プランBの必要性について書いたことがあります。あなたがいつも使っている大規模な言語モデルのAPIが突然廃止されて新しいものに置き換えられたらどうなるでしょうか。

## AIモデル革命：多様なエコシステムの出現

しかし、わずか数ヶ月で状況は一変しました。AnthropicとGoogleは、OpenAIとほぼ同等の高度なAIモデルをリリースしました。さらに重要なことに、Meta、Apple、Microsoftなどの大手テック企業が自社のモデルをオープンソース化し、ダウンロードできるようにしたのです。つまり、APIを介してアクセスするだけでなく、自社のインフラでモデルを実行できるようになったのです。これは、データを見知らぬところに送ることを伴うため、快適ではない人もいます。

突然、私のツールボックスは、それぞれ独自の特徴と能力を持つ光り輝く新しいツールでいっぱいになり、AIモデルの状況は多様なエコシステムへと変貌しました。Llama 3のような新しいオープンモデルの中には、わずか1年半前のGPTと同等の力を持つものもあり、驚くべきことに、私のMacBook Airでも実行できるものもあります！まるで白黒の世界が突然色鮮やかに爆発したかのようで、AIはかつてないほどアクセスしやすく、多用途になりました。ここ数ヶ月間の最も重要なリリースをいくつか見てみましょう。

## 大規模言語モデルの最近の進歩

• Google Gemini（2023年12月6日）：Googleの高度なモデルラインナップで、1.0、1.5（ProとUltra）のバージョンがあり、最大100万トークンのコンテキストウィンドウを持っています。私はこれらのモデルをかなり使ってきましたが、その発展の仕方が本当に気に入っています。
• Mistral社のMixtral（2023年12月11日）：オープンな重みを持つ高品質のスパースな専門家混合モデル（SMoE）であるMixtral 8x7Bをリリースし、ほとんどの標準的なベンチマークでGPT3.5と同等またはそれ以上の性能を発揮しています。それまでは、Mistralモデルをあまり探求していませんでした。
• GoogleのGemma（2024年2月21日）：Googleの軽量で最先端のオープンモデルのファミリーで、GoogleのGeminiモデルと同じ研究とテクノロジーで構築されており、開発者が高度なAIにアクセスしやすくなっています。驚くほど小さなモデルで、試してみたところ、ある用途では、言語を理解してユーザーとやり取りできるエンジンさえあればいいのだと気づきました。今では、OpenAIに頼ることなく、自分のマシンで実行できるソフトウェアにそのような機能を組み込むことができるのです。
• Anthropic Claude 3（2024年3月4日）：AnthropicのHaiku、Sonnet、Opusを含む最新の製品で、私はしばらくの間、これらのモデルへの研究アクセス権を幸運にも持っていました。私の意見では、現時点ではOpenAIのモデルに対する最も強力な代替手段です。特にOpusは温かみがあり、魅力的で、深い知的な会話に参加し、高度な推論能力を発揮できるデジタルパーソナリティを構築するための素晴らしいモデルです。
• X社のGrok（2024年3月18日リリース）：「オープンソース言語モデル」として発表されましたが、同社はコードや文書をほとんど公開せずに、一般に重みのみを公開したため、多くの開発者がその実際の能力と使用可能性について不明確です。私はそれを試してみたいのですが、現時点では自分のハードウェアやクラウドで実行するには大きすぎます。
• AppleのMM1（2024年3月19日リリース）：Appleが人工知能を非常に真剣に受け止めていることを明確に示すマルチモーダルな大規模言語モデルです。私はまだそれを試す機会がありません。
• DatabricksのDBRX（2024年3月27日）：細かい粒度の専門家混合（MoE）アーキテクチャを導入したオープンモデルで、GPTよりも少ないパラメータで印象的なパフォーマンスを達成しています。これは、企業が自社のインフラで強力なAIモデルを実行する能力を提供するため、企業の顧客にとって非常に興味深いものになる可能性があります。データコンプライアンスや特定のユースケースにモデルを微調整する能力など、企業のニーズにフォーカスしたDatabricksの取り組みは、多くの企業にとってDBRXを魅力的な選択肢にしています。
• MetaのLlama 3（2024年4月18日）：Metaの最新のオープンモデルで、膨大なデータセットでトレーニングされ、わずか1年半前のGPTに匹敵するパフォーマンスを発揮します。出力の品質、カスタムプロンプトへの反応、そしてその多機能性と使いやすさに、私は非常に感銘を受けました。もちろん、以前にLLama 2を見たことはありましたが、あまり使いませんでした。Facebook、WhatsApp、Instagramには、Llama 3が搭載された機能が組み込まれています。モデルをトレーニングするための新鮮なデータを入手することが、現在のAI企業にとって大きな問題だと考えると、これらのプラットフォームがどれだけ何十億人ものユーザーを抱えているかを考えてみてください。Metaは非常に有利な立場にあります。人間のフィードバックを用いた強化学習は、AIモデルをより賢くし、次世代を生み出すための鍵なのです。
• MicrosoftのPhi-3（2024年4月23日）：効率とパフォーマンスを重視して設計された小型言語モデル（SLM）のファミリーで、特にエッジコンピューティングやオフラインのシナリオに適しています。私はPhi-3モデルとの最初のインタラクションを楽しみましたし、生のパワーよりもスピード、プライバシー、デバイスの機能を優先するアプリケーションで、彼らが強力なニッチを見つけると信じています。

このタイムラインは、わずか数ヶ月でのイノベーションの速いペースとAIモデル環境の多様性の高まりを示しています。それぞれのリリースが新しい機能、アーキテクチャ、潜在的なユースケースをもたらし、開発者や企業に豊富な選択肢を提供しているのです。

## OpenAIとより効率的なAIアーキテクチャの台頭

しかし、これらすべてにおいてOpenAIはどこにいるのでしょうか。超有名なChatGPTを運営し、そのGPTモデルでAI環境の大部分を支配しているこの企業は、最近のリリースラッシュから目立って欠けています（ちょっとSORAの発表は無視しますが）。彼らは舞台裏でGPT-5に取り組んでいるかもしれませんが、特に専門家混合（MoE）技術を使用したいくつかの新しいアーキテクチャが、GPTの優位性に挑戦し始めているのは明らかです。

DBRXやLlama 3のようなモデルは、より少ないパラメータとより効率的なアーキテクチャで印象的なパフォーマンスを達成できることを示しました。そして、より小さなインフラ要件でより良い結果を提供できるMoEモデルへの移行は、GPTがかつて持っていた競争上の優位性を浸食することで、事実上OpenAIの昼食を食べているのです。

それでは、このAIモデルの選択肢と利用しやすさの新時代をどのようにナビゲートして、自分のニーズに最も適したものを見つけるのでしょうか。

## AIモデルの多様性を活用する

AIモデルの選択肢と利用しやすさのこの新時代をナビゲートする際、ワンサイズフィットオールの解決策はないことを認識することが重要です。私たちの脳が、自動的で無意識のもの（靴ひもを結ぶことなど）から、意図的で分析的なもの（複雑な数学の問題を解くことなど）まで、さまざまなタスクに異なるシステムを採用しているように、私たちは特定の目的のために異なるAIモデルを活用することができるのです。

ダニエル・カーネマン心理学者は、著書「ファスト＆スロー」の中で、私たちの心の中には2つの異なるシステムがあるという概念を紹介しています。自動的に素早く動作するシステム1と、より努力を要する精神活動に注意を向けるシステム2です。私たちはこのフレームワークをAIモデルの世界に適用することができます。迅速な応答と最小限の計算リソースを必要とするタスク（システム1に似ている）には、より小さく効率的なモデルを使用し、より深い推論と分析を必要とするタスク（システム2に似ている）には、より大きく複雑なモデルを使用するのです。

さらに、特定のタスクに優れたモデルを組み合わせることで、強力で多面的なAIシステムを作ることができます。例えば、エッジコンピューティングやオフラインのシナリオにはPhi-3のようなモデルを使い、軽量なデバイス上の処理にはGemmaを、より複雑なクラウドベースのタスクにはDBRXやLlama 3を使うことができます。各モデルの長所と短所を理解し、戦略的に組み合わせることで、より効率的で効果的で、幅広いユースケースに適応できるAIアプリケーションを構築することができるのです。

## 柔軟で洞察力のあるアプローチを使うことができます

結局のところ、この新しい環境で成功するカギは、柔軟で洞察力のあるマインドセットでAIモデルの選択と導入に取り組むことです。最新の動向を把握し、さまざまなモデルを試し、各プロジェクトの具体的なニーズと制約を慎重に検討することで、開発者や企業は、単一のモデルやプロバイダーに過度に依存するという落とし穴を避けながら、この新しいAI時代の力を活用することができるのです。

AIにとってエキサイティングな時期であり、私たちが前進するにつれ、AIモデル環境の多様性とアクセシビリティを受