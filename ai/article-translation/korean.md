# AI 포스의 각성

OpenAI의 GPT가 대부분의 AI 프로젝트에서 기본 선택이었던 것 기억나시나요? 이제 불과 몇 달 만에 AI 환경이 완전히 뒤바뀌었습니다. Meta, Microsoft, Databricks, Apple과 같은 기술 대기업들이 자체 오픈 모델을 발표했기 때문입니다. 이 새로운 선택과 접근성의 시대가 우리가 스마트 애플리케이션을 구축하는 방식을 어떻게 변화시키고 있는지, 왜 만능 해결책이 없는지, 그리고 이 빠르게 진화하는 환경에서 어떻게 자신의 필요에 가장 적합한 접근 방식을 찾을 수 있는지 살펴보겠습니다.

작년 말까지만 해도 AI를 사용하여 스마트 애플리케이션을 구축하는 것에 대해 질문을 받으면, 당시에는 OpenAI의 GPT가 아마도 유일한 실행 가능한 옵션이었다고 마지못해 인정했을 것입니다. 마치 하나의 도구만 있는 도구 상자와 같았죠. 아니면 많은 강력한 도구들이 있지만, 모두 같은 브랜드에서 나온 것으로 같은 제한과 특성을 가지고 있다고 할 수 있습니다. 저는 GPT-2, GPT-3, 그리고 모든 .5와 터보 버전을 사용해 본 경험으로 GPT 제품군에 매우 익숙합니다. 오해하지 마세요, 그들은 훌륭합니다. 하지만 제가 말했듯이, 모두 한 회사에서 나온 것입니다. 저는 이전에 플랜 B의 필요성에 대해 글을 쓴 적이 있습니다. 자주 사용하던 대형 언어 모델 API가 갑자기 중단되고 새로운 것으로 대체되면 어떻게 될까요?

## AI 모델 혁명: 다양한 생태계의 등장

하지만 불과 몇 달 만에 모든 것이 바뀌었습니다. Anthropic과 Google은 OpenAI만큼 강력한 고급 AI 모델을 발표했습니다. 더 중요한 것은 Meta, Apple, Microsoft와 같은 기술 대기업들이 자사 모델을 오픈 소스로 제공하고 다운로드할 수 있게 만들었다는 점입니다. 이는 API를 통해 접근하는 것이 아니라 자체 인프라에서 모델을 실행할 수 있다는 것을 의미합니다. 데이터를 알 수 없는 곳으로 보내는 것을 꺼리는 사람들에게는 불편한 일이었죠.

갑자기 제 도구 상자는 각각 고유한 기능과 능력을 가진 반짝이는 새 도구들로 가득 찼고, AI 모델 환경은 다양한 생태계로 변모했습니다. Llama 3와 같은 일부 새로운 오픈 모델은 이제 불과 1년 반 전의 GPT만큼 강력해졌고, 심지어 일부는 제 MacBook Air에서도 실행될 수 있었습니다! 마치 흑백 세상이 갑자기 색깔로 폭발하는 것을 보는 것 같았죠. AI가 그 어느 때보다 접근성이 높아지고 다재다능해졌습니다. 지난 몇 달 동안 가장 중요한 발표들을 살펴보겠습니다.

## 대형 언어 모델의 최근 발전

• Google Gemini (2023년 12월 6일): Google의 고급 모델 라인업으로 1.0, 1.5(Pro 및 Ultra) 버전이 포함되며 최대 100만 개의 토큰 컨텍스트 윈도우를 제공합니다. 저는 이 모델들을 꽤 많이 다뤄봤는데, 정말 그들의 발전 방향이 마음에 듭니다.
• Mistral의 Mixtral (2023년 12월 11일): 개방형 가중치를 가진 고품질 SMoE(Sparse Mixture of Experts) 모델인 Mixtral 8x7B를 발표했으며, 대부분의 표준 벤치마크에서 GPT3.5와 동등하거나 우수한 성능을 보입니다. 그때까지 저는 Mistral 모델을 많이 탐색하지 않았습니다.
• Google의 Gemma (2024년 2월 21일): Google의 Gemini 모델과 동일한 연구 및 기술로 구축된 경량의 최첨단 오픈 모델 제품군으로, 개발자들이 고급 AI에 더 쉽게 접근할 수 있도록 합니다. 그들은 놀라울 정도로 작은 모델이며, 제가 사용해 보았을 때 일부 사용 사례의 경우 우리에게 정말 필요한 것은 언어를 이해하고 사용자와 상호 작용할 수 있는 엔진이라는 것을 깨달았습니다. 이제 우리는 OpenAI에 의존하지 않고도 제 자신의 기기에서 실행할 수 있는 소프트웨어에 이러한 기능을 내장할 수 있게 되었습니다.
• Anthropic Claude 3 (2024년 3월 4일): Anthropic의 최신 제품으로는 Haiku, Sonnet, Opus가 있으며, 저는 이 모델들에 대한 연구 접근 권한을 얻을 수 있는 행운을 누렸습니다. 제 의견으로는 현재 OpenAI 모델의 가장 강력한 대안입니다. 특히 Opus는 따뜻하고 매력적이며, 깊이 있는 지적 대화에 참여하고 고급 추론 능력을 보여줄 수 있는 디지털 인격을 구축하기에 훌륭한 모델입니다.
• X의 Grok (2024년 3월 18일 출시): "오픈 소스 언어 모델"로 발표되었지만, 회사는 코드나 문서 없이 대중에게 가중치만 공개했기 때문에 많은 개발자들이 실제 기능과 사용 가능성에 대해 확신하지 못하고 있습니다. 저는 그것을 시도해 보고 싶지만, 현재로서는 제 하드웨어나 클라우드에서 실행하기에는 너무 큽니다.
• Apple의 MM1 (2024년 3월 19일 출시): Apple이 AI를 매우 진지하게 받아들이고 있다는 사실을 분명히 보여주는 멀티모달 대형 언어 모델입니다. 아직 사용해 볼 기회는 없었습니다.
• Databricks의 DBRX (2024년 3월 27일): 세분화된 전문가 혼합(MoE) 아키텍처를 도입한 오픈 모델로, GPT보다 적은 매개변수로 인상적인 성능을 달성합니다. 이는 기업들이 자체 인프라에서 강력한 AI 모델을 실행할 수 있는 능력을 제공하기 때문에 기업 고객들에게 매우 흥미로울 수 있습니다. 데이터 규정 준수와 특정 사용 사례에 맞게 모델을 미세 조정할 수 있는 능력과 같은 기업의 요구 사항에 중점을 둔 Databricks의 노력은 DBRX를 많은 비즈니스에 매력적인 선택으로 만듭니다.
• Meta의 Llama 3 (2024년 4월 18일): Meta의 최신 오픈 모델로, 방대한 데이터 세트에서 학습되었으며 불과 1년 반 전의 GPT와 견줄 만한 성능을 제공합니다. 저는 출력 품질, 사용자 정의 프롬프트에 대한 반응, 그리고 그것의 다재다능함과 사용 가능성에 깊은 인상을 받았습니다. 물론 저는 이전에 LLama 2를 보기는 했지만 많이 사용하지는 않았습니다. 이제 Facebook, WhatsApp, Instagram에는 LLama 3 기반의 기능이 내장되어 있습니다. 현재 AI 회사들에게 모델 학습을 위한 새로운 데이터를 확보하는 것이 엄청난 문제라는 점을 고려할 때, 이 플랫폼들이 얼마나 많은 수십억 명의 사용자를 보유하고 있는지 생각해 보세요. Meta는 매우 좋은 위치에 있습니다. 인간 피드백을 통한 강화 학습은 AI 모델을 더 스마트하게 만들고 다음 세대를 만드는 열쇠입니다.
• Microsoft의 Phi-3 (2024년 4월 23일): 효율성과 성능을 위해 설계된 소형 언어 모델(SLM) 제품군으로, 특히 엣지 컴퓨팅 및 오프라인 시나리오에 적합합니다. 저는 Phi-3 모델과의 첫 번째 상호 작용을 즐겼으며, 그들이 속도, 개인 정보 보호 및 기기 기능을 원시적인 성능보다 우선시하는 애플리케이션에서 강력한 틈새 시장을 찾을 것이라고 믿습니다.

이 타임라인은 불과 몇 달 만에 혁신의 빠른 속도와 AI 모델 환경의 증가하는 다양성을 보여줍니다. 각 출시는 새로운 기능, 아키텍처 및 잠재적 사용 사례를 가져와 개발자와 기업에게 풍부한 선택권을 제공합니다.

## OpenAI와 더 효율적인 AI 아키텍처의 부상

그러나 이 모든 것에서 OpenAI는 어디에 있을까요? 초유명 ChatGPT를 운영하고 GPT 모델로 대부분의 AI 환경을 지배하는 이 회사는 최근의 출시 물결에서 눈에 띄게 부재했습니다(잠시 SORA 발표를 무시한다면). 그들이 막후에서 GPT-5를 개발하고 있을지도 모르지만, 특히 전문가 혼합(MoE) 기술을 사용하는 일부 최신 아키텍처가 GPT의 패권에 도전하기 시작한 것은 분명합니다.

DBRX와 Llama 3와 같은 모델은 더 적은 매개변수와 더 효율적인 아키텍처로 인상적인 성능을 달성할 수 있음을 보여주었습니다. 그리고 더 작은 인프라 요구 사항으로 더 나은 결과를 제공할 수 있는 MoE 모델로의 전환은 GPT가 한때 가지고 있던 경쟁 우위를 침식함으로써 사실상 OpenAI의 점심을 먹고 있습니다.

그렇다면, 우리는 이 새로운 AI 모델 선택과 접근성의 시대에서 어떻게 우리의 필요에 가장 적합한 것을 찾아낼 수 있을까요?

## AI 모델의 다양성 활용하기

우리가 이 새로운 AI 모델 선택과 접근성의 시대를 헤쳐나갈 때, 만능 해결책은 없다는 것을 인식하는 것이 중요합니다. 우리의 두뇌가 자동적이고 무의식적인 것(신발 끈 묶기)에서부터 신중하고 분석적인 것(복잡한 수학 문제 해결)에 이르기까지 다양한 작업에 서로다른 시스템을 사용하는 것처럼, 우리는 특정 목적에 맞게 다양한 AI 모델을 활용할 수 있습니다.

그의 저서 "빠르게 생각하기, 느리게 생각하기"에서 심리학자 Daniel Kahneman은 우리 마음속에 두 가지 별개의 시스템이 있다는 개념을 소개합니다. 자동적이고 빠르게 작동하는 시스템 1과 더 노력이 필요한 정신 활동에 주의를 기울이는 시스템 2입니다. 우리는 이 프레임워크를 AI 모델의 세계에 적용할 수 있습니다. 빠른 응답과 최소한의 계산 자원이 필요한 작업(시스템 1과 유사)에는 더 작고 효율적인 모델을 사용하고, 더 깊이 있는 추론과 분석이 필요한 작업(시스템 2와 유사)에는 더 크고 복잡한 모델을 사용하는 것입니다.

더 나아가 우리는 특정 작업에서 탁월한 모델을 결합하여 강력하고 다면적인 AI 시스템을 만들 수 있습니다. 예를 들어, 우리는 엣지 컴퓨팅 및 오프라인 시나리오를 위해 Phi-3와 같은 모델을 사용하고, 경량의 기기 내 처리를 위해 Gemma를, 더 복잡한 클라우드 기반 작업을 위해 DBRX 또는 Llama 3를 사용할 수 있습니다. 각 모델의 장단점을 이해하고 전략적으로 결합함으로써, 우리는 더 효율적이고 효과적이며 다양한 사용 사례에 적응할 수 있는 AI 애플리케이션을 구축할 수 있습니다.

## 유연하고 통찰력 있는 접근 방식을 사용할 수 있습니다

궁극적으로 이 새로운 환경에서 성공의 열쇠는 유연하고 통찰력 있는 사고방식으로 AI 모델 선택과 배포에 접근하는 것입니다. 최신 개발 동향을 파악하고, 다양한 모델을 실험하며, 각 프로젝트의 구체적인 요구 사항과 제약 조건을 신중하게 고려함으로써 개발자와 기업은 단일 모델이나 공급자에 과도하게 의존하는 함정을 피하면서 이 새로운 AI 시대의 힘을 활용할 수 있습니다.

AI에게는 흥미진진한 시기이며, 우리가 앞으로 나아갈 때 AI 모델 환경의 다양성과 접근성을 수용합시다. 이는 분명히 인공지능의 민주화와 발전에 있어 중요한 진전을 나타내기 때문입니다.