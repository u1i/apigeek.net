# Ang Paggising ng Puwersa ng AI

Natatandaan mo ba noong ang GPT ng OpenAI ang default na pagpipilian para sa karamihan ng mga proyektong AI? Ngayon, ang mundo ng AI ay nabaliktad na lamang sa loob ng ilang buwan, kasama ang mga higanteng kumpanya ng teknolohiya tulad ng Meta, Microsoft, Databricks, at Apple na naglabas ng kanilang sariling mga bukas na modelo. Tingnan natin kung paano binabago ng bagong panahon ng pagpipilian at pagiging madaling ma-access ang paraan natin ng pagbuo ng mga matalinong aplikasyon, kung bakit walang iisang solusyon na angkop sa lahat, at kung paano mo manaviga ang mabilis na umuunlad na mundong ito upang mahanap ang pinakamahusay na diskarte na akma sa iyong mga pangangailangan.

Hanggang sa katapusan ng nakaraang taon, kapag tinanong tungkol sa pagbuo ng mga matalinong aplikasyon gamit ang AI, labag sa loob kong aaminin na ang GPT ng OpenAI marahil ang tanging praktikal na opsyon sa oras na iyon. Parang may isang kahon ng kasangkapan na may isang tool lamang - o sabihin nating maraming makapangyarihang tool, ngunit lahat ay mula sa iisang tatak, na may parehong mga limitasyon at mga kababalaghan. Lubos kong kilala ang pamilya ng GPT, matapos magtrabaho sa GPT-2, GPT-3, at lahat ng mga baryante ng .5 at turbo. Huwag mo akong maunawaan nang mali, ang mga ito ay mahusay, ngunit tulad ng sinabi ko, iisa lang ang kumpanya. Dati nang nasulat ko ang tungkol sa pangangailangan para sa isang plano B. Ano ang mangyayari kapag ang iyong madalas gamitin na API ng malaking modelo ng wika ay biglang hindi na ginagamit at pinalitan ng bago?

## Rebolusyon ng Modelo ng AI: Isang Magkakaibang Ecosystem ang Lumilitaw

Ngunit pagkatapos, sa loob lamang ng ilang buwan, nagbago ang lahat. Ang Anthropic at Google ay naglabas ng mga advanced na modelo ng AI na halos kasing galing ng sa OpenAI. Mas mahalaga pa, ang mga higanteng kumpanya ng teknolohiya tulad ng Meta, Apple, at Microsoft ay ginawang open source at available for download ang kanilang mga modelo. Ibig sabihin nito ay maaari mong patakbuhin ang mga ito sa iyong sariling imprastraktura sa halip na i-access lamang ang mga ito sa pamamagitan ng API, na hindi komportable para sa ilang tao dahil sangkot dito ang pagpapadala ng iyong data sa hindi alam.

Biglang-bigla, ang aking kahon ng kasangkapan ay puno ng mga makintab na bagong tool, bawat isa ay may sariling natatanging mga tampok at kakayahan, at ang mundo ng modelo ng AI ay naging isang magkakaibang ecosystem. Ang ilan sa mga bagong bukas na modelo na ito, tulad ng Llama 3 ay ngayon ay kasing lakas na ng GPT 1.5 taon pa lang ang nakakaraan, at ang ilan, nakakabilib, ay maaari pang tumakbo sa aking MacBook Air! Para itong panonood sa isang itim at puting mundo na biglang sumabog sa kulay habang ang AI ay nagiging mas madaling ma-access at mas maaaring gamitin kaysa dati. Tingnan natin ang ilan sa pinakamahalagang mga inilabas sa nakaraang ilang buwan.

## Mga Kamakailang Pag-unlad sa Malalaking Modelo ng Wika

• Google Gemini (Disyembre 6, 2023): Ang hanay ng advanced na modelo ng Google, kabilang ang mga bersyon 1.0, 1.5 (Pro at Ultra) na may mga context window na hanggang 1 milyong token - nagtrabaho ako nang husto sa mga ito, at talagang gusto ko kung paano sila umuunlad.
• Mixtral mula sa Mistral (Disyembre 11, 2023): paglabas ng Mixtral 8x7B, isang de-kalidad na sparse mixture of experts model (SMoE) na may mga bukas na timbang na tumutugma o humihigit sa GPT3.5 sa karamihan ng mga karaniwang benchmark. Hanggang sa panahong iyon hindi ko pa masyadong natuklas ang mga modelo ng Mistral.
• Gemma ng Google (Pebrero 21, 2024): Isang pamilya ng magagaan, modernong mga bukas na modelo na binuo mula sa parehong pananaliksik at teknolohiya ng mga modelo ng Gemini ng Google, na ginagawang mas madaling ma-access ng mga developer ang advanced AI. Ang mga ito ay kamangha-manghang maliliit na modelo, at nang subukan ko ang mga ito, napagtanto ko na para sa ilang mga use case, kailangan lang talaga natin ng isang makina na nakakaunawa ng wika at nakikipag-ugnayan sa mga user. Ngayon, magagawa nating magkaroon ng mga kakayahang iyon na naka-embed sa software na maaari kong patakbuhin sa sarili kong machine, at hindi ko na kailangang umasa sa OpenAI.
• Anthropic Claude 3 (Marso 4, 2024): Kabilang sa mga pinakabagong inaalok ng Anthropic ang Haiku, Sonnet, at Opus, at mapalad akong magkaroon ng access sa pananaliksik sa mga modelo na ito sa ilang panahon na ngayon. Sa aking opinyon, sila ang pinakamakapangyarihang mga alternatibo sa mga modelo ng OpenAI sa ngayon. Lalo na ang Opus ay pakiramdam ay mainit, nakakaakit, at isang kahanga-hangang modelo para sa pagbuo ng mga digital na personalidad na maaaring makisali sa malalim na intelektwal na pag-uusap at magpakita ng advanced na kakayahan sa pangangatuwiran.
• Grok ng X (inilabas noong Marso 18, 2024): Inihayag bilang isang "Open Source language model", ang kumpanya ay naglabas lamang ng mga timbang sa publiko, nang walang code o maraming dokumentasyon, na nag-iiwan sa maraming developer na hindi tiyak tungkol sa tunay nitong mga kakayahan at pagiging magagamit. Sabik akong subukan ito, ngunit masyadong malaki ito sa ngayon para patakbuhin sa sarili kong hardware o sa cloud.
• MM1 ng Apple (inilabas noong Marso 19, 2024): isang multimodal na malaking modelo ng wika na malinaw na nagpapahiwatig ng katotohanan na sineseryoso ng Apple ang AI. Hindi pa ako nagkaroon ng pagkakataong subukan ito.
• DBRX ng Databricks (Marso 27, 2024): Isang bukas na modelo na nagpapakilala ng isang fine-grained mixture-of-experts (MoE) architecture, na nakakamit ng kahanga-hangang performance na may mas kaunting mga parameter kaysa sa GPT. Maaari itong maging napakainteresante para sa mga kumpanya ng enterprise, dahil binibigyan nito sila ng kakayahang magpatakbo ng mga makapangyarihang modelo ng AI sa kanilang sariling imprastraktura. Ang pagtuon ng Databricks sa mga pangangailangan ng enterprise tulad ng pagsunod sa data at ang kakayahang i-fine-tune ang mga modelo para sa mga partikular na use case ay ginagawang isang kaakit-akit na pagpipilian ang DBRX para sa maraming negosyo.
• Llama 3 ng Meta (Abril 18, 2024): Ang pinakabagong bukas na modelo ng Meta, na sinanay sa isang napakalaking dataset at nag-aalok ng performance na katumbas ng GPT mula sa 1.5 taon pa lang ang nakakaraan. Lubos akong humahanga sa kalidad ng output, kung paano ito tumutugon sa mga custom na prompt, at kung gaano ito kabisa at magagamit. Siyempre nakita ko na ang LLama 2 dati ngunit hindi gaanong ginamit. Ang Facebook, WhatsApp, at Instagram ngayon ay may mga kakayahang pinapagana ng LLama 3 na naka-embed. Kapag iniisip mo kung gaano kalaking problema para sa mga kumpanya ng AI ang pagkuha ng sariwang data upang sanayin ang kanilang mga modelo sa ngayon, isipin mo kung ilang bilyong user ang mayroon ang mga platform na ito. Ang Meta ay nasa napakagandang posisyon. Ang reinforcement learning na may feedback ng tao ang susi sa paggawa ng mga modelo ng AI na mas matalino at paglikha ng susunod na henerasyon.
• Phi-3 ng Microsoft (Abril 23, 2024): Isang pamilya ng maliliit na modelo ng wika (SLMs) na idinisenyo para sa kahusayan at pagganap, partikular na angkop para sa edge computing at mga sitwasyon offline. Nasiyahan ako sa aking unang hanay ng mga pakikipag-ugnayan sa mga modelo ng Phi-3 at naniniwala ako na matatagpuan nila ang isang malakas na niche sa mga aplikasyon na nagbibigay prayoridad sa bilis, privacy, at mga kakayahan sa device kaysa sa hilaw na kapangyarihan.

Ipinapakita ng timeline na ito ang mabilis na bilis ng innovation at ang lumalaking pagkakaiba-iba ng mundo ng modelo ng AI sa loob lamang ng ilang buwan. Ang bawat pagpapalabas ay nagdadala ng mga bagong kakayahan, arkitektura, at mga potensyal na use case, na nagbibigay sa mga developer at negosyo ng napakaraming mga pagpipilian.

## OpenAI at ang Pagtaas ng Mas Mahusay na mga Arkitektura ng AI

Ngunit nasaan ang OpenAI sa lahat ng ito? Ang kumpanya na nagpapatakbo ng ultra prominent na ChatGPT at nananatiling nangingibabaw sa karamihan ng mundo ng AI sa pamamagitan ng mga modelo nito ng GPT ay kapansin-pansing nawawala mula sa kamakailang bugso ng mga pagpapalabas (kung hindi mo papansinin ang anunsyo ng SORA sa isang saglit). Habang maaaring nagtatrabaho sila sa GPT-5 sa likod ng mga eksena, malinaw na ang ilan sa mga mas bagong arkitektura, partikular na iyong gumagamit ng mga teknolohiyang mixture-of-experts (MoE), ay nagsisimulang hamunin ang pagiging nangingibabaw ng GPT.

Ipinapakita ng mga modelo tulad ng DBRX at Llama 3 na posibleng makamit ang kahanga-hangang performance na may mas kaunting mga parameter at mas mahusay na mga arkitektura. At ang paglipat patungo sa mga modelo ng MoE, na maaaring maghatid ng mas mahusay na mga resulta na may mas maliit na mga pangangailangan sa imprastraktura, ay epektibong kumakain sa tanghalian ng OpenAI sa pamamagitan ng pagkasira ng competitive advantage na minsan ay hawak ng GPT.

Kaya - paano natin manaviga ang bagong panahon na ito ng pagpipilian at pagiging madaling ma-access ng modelo ng AI upang mahanap ang pinakamahusay na angkop sa ating mga pangangailangan?

## Paggamit ng Pagkakaiba-iba ng mga Modelo ng AI

Habang ninanaviga natin ang bagong panahon na ito ng pagpipilian at pagiging madaling ma-access ng modelo ng AI, mahalagang kilalanin na walang iisang solusyon na angkop sa lahat. Tulad ng paggamit ng ating mga utak ng iba't ibang mga sistema para sa iba't ibang mga gawain, mula sa awtomatiko at hindi sinasadya (tulad ng pagtatali ng ating mga sapatos) hanggang sa sadya at pag-aanalisa (tulad ng paglutas ng isang kumplikadong problema sa matematika), maaari nating gamitin ang iba't ibang mga modelo ng AI para sa mga partikular na layunin.

Sa kanyang aklat na "Thinking, Fast and Slow," ipinakilala ng sikolohista na si Daniel Kahneman ang konsepto ng dalawang magkaibang sistema sa ating mga isip: Ang System 1, na gumagana nang awtomatiko at mabilis, at ang System 2, na naglalaan ng pansin sa mas nakakapagod na mga aktibidad ng isip. Maaari nating ilapat ang balangkas na ito sa mundo ng mga modelo ng AI, gamit ang mas maliliit, mas mahusay na mga modelo para sa mga gawain na nangangailangan ng mabilis na tugon at pinakamaliit na mga mapagkukunan sa pagkompyut (katulad ng System 1) at mas malalaki, mas kumplikadong mga modelo para sa mga gawain na nangangailangan ng mas malalim na pangangatwiran at pagsusuri (katulad ng System 2).

Bukod dito, maaari nating pagsamahin ang mga modelo na mahusay sa mga partikular na gawain upang lumikha ng makapangyarihan, multi-faceted na mga sistema ng AI. Halimbawa, maaari nating gamitin ang isang modelo tulad ng Phi-3 para sa edge computing at mga sitwasyon offline, Gemma para sa magaan, on-device na pagproseso, at DBRX o Llama 3 para sa mas kumplikadong mga gawain na batay sa cloud. Sa pamamagitan ng pag-unawa sa mga kalakasan at kahinaan ng bawat modelo at estratehikong pagsasama sa mga ito, maaari tayong bumuo ng mga aplikasyon ng AI na mas mahusay, mabisa, at madaling mag-adapt sa malawak na hanay ng mga use case.

## Maaari Kang Gumamit ng isang Flexible, Maalam na Diskarte

Sa huli, ang susi sa tagumpay sa bagong mundong ito ay ang pagsasagawa ng pagpili at pag-deploy ng modelo ng AI na may isang flexible, maalam na pag-iisip. Sa pamamagitan ng pananatiling updated sa mga pinakabagong pag-unlad, pag-eksperimento sa iba't ibang mga modelo, at maingat na pagsasaalang-alang sa mga partikular na pangangailangan at limitasyon ng bawat proyekto, ang mga developer at negosyo ay maaaring magamit ang kapangyarihan ng bagong panahon na ito ng AI habang iniiwasan ang mga bitag ng labis na pag-asa sa anumang iisang modelo o provider.

Ito ay isang kapana-panabik na panahon para sa AI, at habang tayo ay sumusulong, yakapin natin ang pagkakaiba-iba at pagiging madaling ma-access ng mundo ng modelo ng AI, dahil malinaw na kumakatawan ito sa isang makabuluhang hakbang pasulong sa demokratisasyon at pag-unlad ng artipisyal na katalinuhan.