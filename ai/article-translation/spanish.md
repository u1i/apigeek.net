# El Despertar de la Fuerza de la IA

¿Recuerdas cuando el GPT de OpenAI era la opción predeterminada para la mayoría de los proyectos de IA? Ahora, el panorama de la IA se ha puesto patas arriba en solo unos pocos meses, con gigantes tecnológicos como Meta, Microsoft, Databricks y Apple lanzando sus propios modelos abiertos. Veamos cómo esta nueva era de elección y accesibilidad está cambiando la forma en que construimos aplicaciones inteligentes, por qué no existe una solución única para todos y cómo puedes navegar en este panorama que evoluciona rápidamente para encontrar el mejor enfoque que se adapte a tus necesidades.

Hasta finales del año pasado, cuando me preguntaban sobre la construcción de aplicaciones inteligentes utilizando IA, habría admitido a regañadientes que el GPT de OpenAI probablemente era la única opción viable en ese momento. Era como tener una caja de herramientas con una sola herramienta, o digamos muchas herramientas poderosas, pero todas de la misma marca, con las mismas limitaciones y peculiaridades. Estoy profundamente familiarizado con la familia GPT, habiendo trabajado con GPT-2, GPT-3 y todas las variantes .5 y turbo. No me malinterpretes, son geniales, pero como dije, todo es de una sola empresa. Anteriormente he escrito sobre la necesidad de un plan B. ¿Qué sucede cuando tu API de modelo de lenguaje grande de confianza queda repentinamente obsoleta y es reemplazada por una nueva?

## Revolución de los Modelos de IA: Surge un Ecosistema Diverso

Pero luego, en solo unos pocos meses, todo cambió. Anthropic y Google han lanzado modelos de IA avanzados que son casi tan capaces como los de OpenAI. Aún más significativo, gigantes tecnológicos como Meta, Apple y Microsoft han hecho que sus modelos sean de código abierto y estén disponibles para descargar. Esto significa que puedes ejecutarlos en tu propia infraestructura en lugar de simplemente acceder a ellos a través de una API, lo que a algunas personas no les gusta ya que implica enviar tus datos a lo desconocido.

De repente, mi caja de herramientas estaba repleta de nuevas y brillantes herramientas, cada una con sus propias características y capacidades únicas, y el panorama de los modelos de IA se había transformado en un ecosistema diverso. Algunos de estos nuevos modelos abiertos, como Llama 3, ahora son tan potentes como el GPT de hace solo 1,5 años, y algunos, increíblemente, ¡incluso podían ejecutarse en mi MacBook Air! Era como ver un mundo en blanco y negro estallar repentinamente en color, ya que la IA se volvió más accesible y versátil que nunca. Echemos un vistazo a algunos de los lanzamientos más importantes de los últimos meses.

## Avances Recientes en Grandes Modelos de Lenguaje

• Google Gemini (6 de diciembre de 2023): La alineación de modelos avanzados de Google, que incluye las versiones 1.0, 1.5 (Pro y Ultra) con ventanas de contexto de hasta 1 millón de tokens. He trabajado bastante con estos y realmente me gusta cómo se están desarrollando.

• Mixtral de Mistral (11 de diciembre de 2023): lanzamiento de Mixtral 8x7B, un modelo de mezcla de expertos dispersos (SMoE) de alta calidad con pesos abiertos que iguala o supera a GPT3.5 en la mayoría de los puntos de referencia estándar. Hasta ese momento, no había explorado mucho los modelos de Mistral.

• Gemma de Google (21 de febrero de 2024): Una familia de modelos abiertos livianos y de última generación construidos a partir de la misma investigación y tecnología que los modelos Gemini de Google, haciendo que la IA avanzada sea más accesible para los desarrolladores. Son modelos notablemente pequeños, y cuando los probé, me di cuenta de que para algunos casos de uso, realmente solo necesitamos un motor que pueda entender el lenguaje e interactuar con los usuarios. Ahora, podemos tener esas capacidades integradas en un software que puedo ejecutar en mi propia máquina, y no necesito depender de OpenAI.

• Anthropic Claude 3 (4 de marzo de 2024): Las últimas ofertas de Anthropic incluyen Haiku, Sonnet y Opus, y he tenido la suerte de tener acceso de investigación a estos durante algún tiempo. En mi opinión, son las alternativas más poderosas a los modelos de OpenAI en este momento. Especialmente Opus se siente cálido, atractivo y es un modelo increíble para construir personalidades digitales que pueden participar en conversaciones intelectuales profundas y mostrar capacidades de razonamiento avanzadas.

• Grok de X (lanzado el 18 de marzo de 2024): Anunciado como un "modelo de lenguaje de código abierto", la empresa solo ha lanzado pesos al público, sin código ni mucha documentación, dejando a muchos desarrolladores inciertos sobre sus capacidades reales y usabilidad. Me encantaría probarlo, pero por ahora es demasiado grande para ejecutarlo en mi propio hardware o en la nube.
• MM1 de Apple (lanzado el 19 de marzo de 2024): un gran modelo de lenguaje multimodal que indica claramente el hecho de que Apple se está tomando muy en serio la IA. Todavía no he tenido la oportunidad de probarlo.

• DBRX de Databricks (27 de marzo de 2024): Un modelo abierto que introduce una arquitectura de mezcla de expertos de grano fino (MoE), logrando un rendimiento impresionante con menos parámetros que GPT. Esto podría ser muy interesante para las empresas, ya que les brinda la capacidad de ejecutar modelos de IA potentes en su propia infraestructura. El enfoque de Databricks en las necesidades empresariales, como el cumplimiento de datos y la capacidad de ajustar los modelos para casos de uso específicos, hace que DBRX sea una opción atractiva para muchos negocios.

• Llama 3 de Meta (18 de abril de 2024): El último modelo abierto de Meta, entrenado en un conjunto de datos masivo y que ofrece un rendimiento comparable al GPT de hace solo 1,5 años. Estoy muy, muy impresionado por la calidad de la salida, cómo reacciona a las indicaciones personalizadas y lo versátil y utilizable que es. Por supuesto, había visto LLama 2 antes pero no lo había usado mucho. Facebook, WhatsApp e Instagram ahora tienen capacidades integradas impulsadas por LLama 3. Cuando piensas en lo grande que es el problema de obtener datos frescos para entrenar sus modelos en este momento para las empresas de IA, considera cuántos miles de millones de usuarios tienen estas plataformas. Meta está en una gran posición. El aprendizaje por refuerzo con retroalimentación humana es la clave para hacer que los modelos de IA sean más inteligentes y crear la próxima generación.

• Phi-3 de Microsoft (23 de abril de 2024): Una familia de pequeños modelos de lenguaje (SLM) diseñados para eficiencia y rendimiento, particularmente adecuados para la computación de borde y escenarios sin conexión. Disfruté mi primer conjunto de interacciones con los modelos Phi-3 y creo que encontrarán un nicho sólido en aplicaciones que priorizan la velocidad, la privacidad y las capacidades del dispositivo sobre la potencia pura.

Esta línea de tiempo muestra el rápido ritmo de innovación y la creciente diversidad del panorama de los modelos de IA en solo unos pocos meses. Cada lanzamiento trae nuevas capacidades, arquitecturas y casos de uso potenciales, brindando a los desarrolladores y empresas una gran cantidad de opciones para elegir.

## OpenAI y el Surgimiento de Arquitecturas de IA Más Eficientes

Pero, ¿dónde está OpenAI en todo esto? La empresa que ejecuta el ultra prominente ChatGPT y aún domina la mayor parte del panorama de la IA con sus modelos GPT ha estado notablemente ausente de la reciente ola de lanzamientos (si ignoras el anuncio de SORA por un momento). Si bien pueden estar trabajando en GPT-5 entre bastidores, está claro que algunas de las arquitecturas más nuevas, particularmente aquellas que utilizan técnicas de mezcla de expertos (MoE), están comenzando a desafiar la supremacía de GPT.

Modelos como DBRX y Llama 3 han demostrado que es posible lograr un rendimiento impresionante con menos parámetros y arquitecturas más eficientes. Y el cambio hacia los modelos MoE, que pueden ofrecer mejores resultados con requisitos de infraestructura más pequeños, está efectivamente comiéndose el almuerzo de OpenAI al erosionar la ventaja competitiva que alguna vez tuvo GPT.

Entonces, ¿cómo navegamos en esta nueva era de elección y accesibilidad de modelos de IA para encontrar lo que mejor se adapte a nuestras necesidades?

## Aprovechando la Diversidad de los Modelos de IA

A medida que navegamos en esta nueva era de elección y accesibilidad de modelos de IA, es esencial reconocer que no existe una solución única para todos. Así como nuestros cerebros emplean diferentes sistemas para diversas tareas, que van desde lo automático e inconsciente (como atarse los zapatos) hasta lo deliberado y analítico (como resolver un problema matemático complejo), podemos aprovechar diferentes modelos de IA para propósitos específicos.

En su libro "Pensar rápido, pensar despacio", el psicólogo Daniel Kahneman introduce el concepto de dos sistemas distintos en nuestras mentes: el Sistema 1, que opera de forma automática y rápida, y el Sistema 2, que asigna atención a actividades mentales más exigentes. Podemos aplicar este marco al mundo de los modelos de IA, utilizando modelos más pequeños y eficientes para tareas que requieren respuestas rápidas y recursos computacionales mínimos (similar al Sistema 1) y modelos más grandes y complejos para tareas que demandan un razonamiento y análisis más profundos (similar al Sistema 2).

Además, podemos combinar modelos que sobresalen en tareas específicas para crear sistemas de IA potentes y multifacéticos. Por ejemplo, podríamos usar un modelo como Phi-3 para computación de borde y escenarios sin conexión, Gemma para procesamiento liviano en dispositivos y DBRX o Llama 3 para tareas más complejas basadas en la nube. Al comprender las fortalezas y debilidades de cada modelo y combinarlos estratégicamente, podemos construir aplicaciones de IA que sean más eficientes, efectivas y adaptables a una amplia gama de casos de uso.

## Puedes Usar un Enfoque Flexible e Informado

En última instancia, la clave del éxito en este nuevo panorama es abordar la selección e implementación de modelos de IA con una mentalidad flexible e informada. Al mantenerse al día con los últimos desarrollos, experimentar con diferentes modelos y considerar cuidadosamente las necesidades y limitaciones específicas de cada proyecto, los desarrolladores y las empresas pueden aprovechar el poder de esta nueva era de la IA mientras evitan las trampas de depender en exceso de cualquier modelo o proveedor único.

Es un momento emocionante para la IA y, a medida que avanzamos, abracemos la diversidad y accesibilidad del panorama de los modelos de IA, ya que esto claramente representa un paso significativo hacia adelante en la democratización y el avance de la inteligencia artificial.